<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Pytorch基本教程</title>
      <link href="/2022/11/10/pytorch.html"/>
      <url>/2022/11/10/pytorch.html</url>
      
        <content type="html"><![CDATA[<p><strong>此博客以机器学习中的一些简单模型为基础，学习Pytorch的基本架构，不做过多深入每个函数的研究与探讨，这部分只需要面向具体的项目代码即可！文章最后面会附上一些相关链接用来参考学习。</strong></p><h1 id="Pytorch基础：Tensor（张量）"><a href="#Pytorch基础：Tensor（张量）" class="headerlink" title="Pytorch基础：Tensor（张量）"></a>Pytorch基础：Tensor（张量）</h1><p>对于张量（Tensor），就可以理解为多为矩阵，也只是一种特别的存储方式而已，当然也可以表示一个元素的张量（或，标量）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.tensor([<span class="number">3.1433223</span>]) </span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br><span class="line">tensor.size()</span><br><span class="line">tensor.item()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">3.1433</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>])</span><br><span class="line"><span class="number">3.143322229385376</span></span><br></pre></td></tr></table></figure><h2 id="Tensor-的基本类型"><a href="#Tensor-的基本类型" class="headerlink" title="Tensor 的基本类型"></a>Tensor 的基本类型</h2><p>Tensor的基本数据类型有五种： </p><ul><li>32位浮点型：torch.FloatTensor。 (默认) </li><li>64位整型：torch.LongTensor。</li><li>32位整型：torch.IntTensor。</li><li>16位整型：torch.ShortTensor。</li><li>64位浮点型：torch.DoubleTensor。</li></ul><p>除以上数字类型外，还有 byte和chart型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">3.1426</span>], dtype=torch.float16)</span><br></pre></td></tr></table></figure><h2 id="设备转换"><a href="#设备转换" class="headerlink" title="设备转换"></a>设备转换</h2><p>相对于 <code>Numpy</code> 中多维矩阵的表示 <code>ndarray</code> 只能在 CPU 上运行，<code>Tensor</code> 可以在 GPU 上运行。所以有时候需要统一好每个 Tensor 所在设备。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用torch.cuda.is_available()来确定是否有cuda设备</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"><span class="comment">#将tensor传送到设备</span></span><br><span class="line">gpu_b=cpu_b.to(device)</span><br><span class="line">gpu_b.<span class="built_in">type</span>()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cuda</span><br><span class="line"><span class="string">&#x27;torch.cuda.FloatTensor&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="Autograd计算梯度数值"><a href="#Autograd计算梯度数值" class="headerlink" title="Autograd计算梯度数值"></a>Autograd计算梯度数值</h1><p>在创建张量时，可以通过设置 <code>requires_grad=True</code>来告诉 Pytorch 对该张量进行自助求导，Pytorch 会记录该张量的每一步操作历史并自动计算梯度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">x</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([[0.0403, 0.5633, 0.2561, 0.4064, 0.9596],</span></span><br><span class="line"><span class="comment">#         [0.6928, 0.1832, 0.5380, 0.6386, 0.8710],</span></span><br><span class="line"><span class="comment">#         [0.5332, 0.8216, 0.8139, 0.1925, 0.4993],</span></span><br><span class="line"><span class="comment">#         [0.2650, 0.6230, 0.5945, 0.3230, 0.0752],</span></span><br><span class="line"><span class="comment">#         [0.0919, 0.4770, 0.4622, 0.6185, 0.2761]], requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">z=x**<span class="number">2</span>+y**<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([[3.3891e-01, 4.9468e-01, 8.0797e-02, 2.5656e-01, 2.9529e-01],</span></span><br><span class="line"><span class="comment">#        [7.1946e-01, 1.6977e-02, 1.7965e-01, 3.2656e-01, 1.7665e-01],</span></span><br><span class="line"><span class="comment">#        [3.1353e-01, 2.2096e-01, 1.2251e+00, 5.5087e-01, 5.9572e-02],</span></span><br><span class="line"><span class="comment">#        [1.3015e+00, 3.8029e-01, 1.1103e+00, 4.0392e-01, 2.2055e-01],</span></span><br><span class="line"><span class="comment">#        [8.8726e-02, 6.9701e-01, 8.0164e-01, 9.7221e-01, 4.2239e-04]],</span></span><br><span class="line"><span class="comment">#       grad_fn=&lt;AddBackward0&gt;)</span></span><br></pre></td></tr></table></figure><p>在张量进行操作后，<code>grad_fn</code> 已经被赋予了一个新的函数，这个函数引用了一个创建了这个 Tensor 类的 Function 对象。 Tensor 和 Function 互相连接生成了一个非循环图，它记录并且编码了完整的计算历史。每个张量都有一个 <code>`.grad_fn</code> 属性，如果这个张量是用户手动创建的那么这个张量的 <code>grad_fn</code> 是 <code>None</code>。</p><p>当计算完成后调用 <code>.backward()</code> 方法自动计算梯度并且将计算结果保存到 <code>grad</code> 属性中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">z.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad,y.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([[1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.]]) </span></span><br><span class="line"><span class="comment"># tensor([[1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1., 1., 1.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们的返回值不是一个标量，所以需要输入一个大小相同的张量作为参数，</span></span><br><span class="line"><span class="comment"># 这里我们用ones_like函数根据x生成一个张量</span></span><br><span class="line">z.backward(torch.ones_like(x))</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([[0.2087, 1.3554, 0.5560, 1.0009, 0.9931],</span></span><br><span class="line"><span class="comment">#        [1.2655, 0.1223, 0.8008, 1.1127, 0.7261],</span></span><br><span class="line"><span class="comment">#        [1.1052, 0.2579, 1.8006, 0.1544, 0.3646],</span></span><br><span class="line"><span class="comment">#        [1.8855, 1.2296, 1.9061, 0.9313, 0.0648],</span></span><br><span class="line"><span class="comment">#        [0.5952, 1.6190, 0.8430, 1.9213, 0.0322]])</span></span><br></pre></td></tr></table></figure><p>我们可以使用 <code>with torch.no_grad()</code> 上下文管理器临时禁止对已设置 <code>requires_grad=True</code> 的张量进行自动求导。这个方法在测试集计算准确率的时候会经常用到，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="built_in">print</span>((x +y*<span class="number">2</span>).requires_grad)</span><br><span class="line">   </span><br><span class="line"><span class="comment"># False</span></span><br></pre></td></tr></table></figure><p>使用 <code>.no_grad()</code> 进行嵌套后，代码不会跟踪历史记录，也就是说保存的这部分记录会减少内存的使用量并且会加快少许的运算速度。</p><h1 id="数据的加载和预处理"><a href="#数据的加载和预处理" class="headerlink" title="数据的加载和预处理"></a>数据的加载和预处理</h1><p>PyTorch通过 <code>torch.utils.data</code> 对一般常用的数据加载进行了封装，可以很容易地实现多线程数据预读和批量加载。 并且 <code>torchvision</code> 已经预先实现了常用图像数据集，包括前面使用过的CIFAR-10，ImageNet、COCO、MNIST、LSUN等数据集，可通过 <code>torchvision.datasets</code> 方便的调用。这里不具体介绍。</p><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>Dataset 是一个抽象类，为了能够方便的读取，需要将要使用的数据包装为 Dataset 类。 自定义的 Dataset 需要继承它并且实现两个成员方法： </p><pre><code>- `__getitem__()` 该方法定义用索引(`0` 到 `len(self)`)获取一条数据或一个样本-  `__len__()` 该方法返回数据集的总长度</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#引用</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义一个数据集</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BulldozerDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 数据集演示 &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, csv_file</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;实现初始化方法，在初始化的时候将数据读载入&quot;&quot;&quot;</span></span><br><span class="line">        self.df=pd.read_csv(csv_file)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        返回df的长度</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.df)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据 idx 返回一行数据</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self.df.iloc[idx].SalePrice</span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># 实例化一个对象访问它</span></span><br><span class="line">ds_demo= BulldozerDataset(<span class="string">&#x27;median_benchmark.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 实现了 __len__ 方法所以可以直接使用len获取数据总数</span></span><br><span class="line"><span class="built_in">len</span>(ds_demo)</span><br><span class="line"><span class="comment"># 用索引可以直接访问对应的数据，对应 __getitem__ 方法</span></span><br><span class="line">ds_demo[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>自定义的数据集已经创建好了，下面我们使用官方提供的数据载入器，读取数据。</p><h2 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h2><p>DataLoader 为我们提供了对 Dataset 的读取操作，常用参数有：</p><ul><li>batch_size(每个batch的大小)、 </li><li>shuffle(是否进行shuffle操作)、 </li><li>num_workers(加载数据的时候使用几个子进程)。</li></ul><p>下面做一个简单的操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dl = torch.utils.data.DataLoader(ds_demo, batch_size=<span class="number">10</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据</span></span><br><span class="line">idata=<span class="built_in">iter</span>(dl)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(idata))</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.], dtype=torch.float64)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 常见的用法是使用for循环对其进行遍历</span></span><br><span class="line"><span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl):</span><br><span class="line">    <span class="built_in">print</span>(i,data)</span><br></pre></td></tr></table></figure><p>我们已经可以通过 Dataset 定义数据集，并使用 Datalorder 载入和遍历数据集，除了这些以外， PyTorch 还提供能 torcvision 的计算机视觉扩展包。</p><h2 id="torchvision-包"><a href="#torchvision-包" class="headerlink" title="torchvision 包"></a>torchvision 包</h2><p>torchvision 是PyTorch中专门用来处理图像的库。</p><h3 id="torchvision-datasets"><a href="#torchvision-datasets" class="headerlink" title="torchvision.datasets"></a>torchvision.datasets</h3><p>torchvision.datasets 可以理解为PyTorch团队自定义的dataset，这些dataset帮我们提前处理好了很多的图片数据集，我们拿来就可以直接使用： - MNIST - COCO - Captions - Detection - LSUN - ImageFolder - Imagenet-12 - CIFAR - STL10 - SVHN - PhotoTour 我们可以直接使用，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line">trainset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, <span class="comment"># 表示 MNIST 数据的加载的目录</span></span><br><span class="line">                          train=<span class="literal">True</span>,    <span class="comment"># 表示是否加载数据库的训练集，false的时候加载测试集</span></span><br><span class="line">                          download=<span class="literal">True</span>, <span class="comment"># 表示是否自动下载 MNIST 数据集</span></span><br><span class="line">                          transform=<span class="literal">None</span>)<span class="comment"># 表示是否需要对数据进行预处理，none为不进行预处理</span></span><br></pre></td></tr></table></figure><h3 id="torchvision-models"><a href="#torchvision-models" class="headerlink" title="torchvision.models"></a>torchvision.models</h3><p>torchvision 不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用，或者在进行迁移学习 <code>torchvision.models</code> 模块的 子模块中包含以下模型结构。 - AlexNet - VGG - ResNet - SqueezeNet - DenseNet</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#我们直接可以使用训练好的模型，当然这个与datasets相同，都是需要从服务器下载的</span></span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">resnet18 = models.resnet18(pretrained=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="torchvision-transforms"><a href="#torchvision-transforms" class="headerlink" title="torchvision.transforms"></a>torchvision.transforms</h3><p>transforms 模块提供了一般的图像转换操作类，用作数据处理和数据增强</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> transforms</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>, padding=<span class="number">4</span>), <span class="comment">#先四周填充0，在把图像随机裁剪成32*32</span></span><br><span class="line">    transforms.RandomHorizontalFlip(),    <span class="comment">#图像一半的概率翻转，一半的概率不翻转</span></span><br><span class="line">    transforms.RandomRotation((-<span class="number">45</span>,<span class="number">45</span>)),  <span class="comment">#随机旋转</span></span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)), <span class="comment">#R,G,B每层的归一化用到的均值和方差</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>肯定有人会问：(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) 这几个数字是什么意思？官方的这个帖子有详细的说明: <a href="https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21">https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21</a> 这些都是根据ImageNet训练的归一化参数，可以直接使用，我们认为这个是固定值就可以。</p><h1 id="神经网络包nn和优化器optimizer"><a href="#神经网络包nn和优化器optimizer" class="headerlink" title="神经网络包nn和优化器optimizer"></a>神经网络包nn和优化器optimizer</h1><p><code>torch.nn</code> 是专门为神经网络设计的模块化接口。<code>nn</code> 构建于 <code>Autograd</code> 之上，可用来定义和运行神经网络。 这里我们主要介绍几个一些常用的类。除了nn别名以外，我们还引用了nn.functional，这个包中包含了神经网络中使用的一些常用函数，这些函数的特点是，不具有可学习的参数(如ReLU，pool，DropOut等)，这些函数可以放在构造函数中，也可以不放，但是这里建议不放。一般情况下我们会<strong>将nn.functional 设置为大写的F</strong>，这样缩写方便调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 首先要引入相关的包</span><br><span class="line">import torch</span><br><span class="line"># 引入torch.nn并指定别名</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br></pre></td></tr></table></figure><h2 id="定义一个网络"><a href="#定义一个网络" class="headerlink" title="定义一个网络"></a>定义一个网络</h2><p>PyTorch 中已经为我们准备好了现成的网络模型，只要继承 <code>nn.Module</code>，并实现它的 <code>forward</code> 方法，PyTorch 会根据 <code>autograd</code>，自动实现 <code>backward</code> 函数，在 <code>forward</code> 函数中可使用任何 tensor 支持的函数，还可以使用 if、for 循环、print、log 等 Python 语法，写法和标准的 Python 写法一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># nn.Module子类的函数必须在构造函数中执行父类的构造函数</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 卷积层 &#x27;1&#x27;表示输入图片为单通道， &#x27;6&#x27;表示输出通道数，&#x27;3&#x27;表示卷积核为3*3</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>) </span><br><span class="line">        <span class="comment">#线性层，输入1350个特征，输出10个特征</span></span><br><span class="line">        self.fc1   = nn.Linear(<span class="number">1350</span>, <span class="number">10</span>)  <span class="comment">#这里的1350是如何计算的呢？这就要看后面的forward函数</span></span><br><span class="line">    <span class="comment">#正向传播 </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): </span><br><span class="line">        <span class="built_in">print</span>(x.size()) <span class="comment"># 结果：[1, 1, 32, 32]</span></span><br><span class="line">        <span class="comment"># 卷积 -&gt; 激活 -&gt; 池化 </span></span><br><span class="line">        x = self.conv1(x) <span class="comment">#根据卷积的尺寸计算公式，计算结果是30，具体计算公式后面第二章第四节 卷积神经网络 有详细介绍。</span></span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        <span class="built_in">print</span>(x.size()) <span class="comment"># 结果：[1, 6, 30, 30]</span></span><br><span class="line">        x = F.max_pool2d(x, (<span class="number">2</span>, <span class="number">2</span>)) <span class="comment">#我们使用池化层，计算结果是15</span></span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        <span class="built_in">print</span>(x.size()) <span class="comment"># 结果：[1, 6, 15, 15]</span></span><br><span class="line">        <span class="comment"># reshape，‘-1’表示自适应</span></span><br><span class="line">        <span class="comment">#这里做的就是压扁的操作 就是把后面的[1, 6, 15, 15]压扁，变为 [1, 1350]</span></span><br><span class="line">        x = x.view(x.size()[<span class="number">0</span>], -<span class="number">1</span>) </span><br><span class="line">        <span class="built_in">print</span>(x.size()) <span class="comment"># 这里就是fc1层的的输入1350 </span></span><br><span class="line">        x = self.fc1(x)        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Net(</span></span><br><span class="line"><span class="comment">#   (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=1350, out_features=10, bias=True)</span></span><br><span class="line"><span class="comment"># )</span></span><br></pre></td></tr></table></figure><p>网络的可学习参数通过 <code>net.parameters()</code> 返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> parameters <span class="keyword">in</span> net.parameters():</span><br><span class="line">    <span class="built_in">print</span>(parameters)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># ----------输出----------</span></span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[[[ <span class="number">0.2745</span>,  <span class="number">0.2594</span>,  <span class="number">0.0171</span>],</span><br><span class="line">          [ <span class="number">0.0429</span>,  <span class="number">0.3013</span>, -<span class="number">0.0208</span>],</span><br><span class="line">          [ <span class="number">0.1459</span>, -<span class="number">0.3223</span>,  <span class="number">0.1797</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.1847</span>,  <span class="number">0.0227</span>, -<span class="number">0.1919</span>],</span><br><span class="line">          [-<span class="number">0.0210</span>, -<span class="number">0.1336</span>, -<span class="number">0.2176</span>],</span><br><span class="line">          [-<span class="number">0.2164</span>, -<span class="number">0.1244</span>, -<span class="number">0.2428</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.1042</span>, -<span class="number">0.0055</span>, -<span class="number">0.2171</span>],</span><br><span class="line">          [ <span class="number">0.3306</span>, -<span class="number">0.2808</span>,  <span class="number">0.2058</span>],</span><br><span class="line">          [ <span class="number">0.2492</span>,  <span class="number">0.2971</span>,  <span class="number">0.2277</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.2134</span>, -<span class="number">0.0644</span>, -<span class="number">0.3044</span>],</span><br><span class="line">          [ <span class="number">0.0040</span>,  <span class="number">0.0828</span>, -<span class="number">0.2093</span>],</span><br><span class="line">          [ <span class="number">0.0204</span>,  <span class="number">0.1065</span>,  <span class="number">0.1168</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.1651</span>, -<span class="number">0.2244</span>,  <span class="number">0.3072</span>],</span><br><span class="line">          [-<span class="number">0.2301</span>,  <span class="number">0.2443</span>, -<span class="number">0.2340</span>],</span><br><span class="line">          [ <span class="number">0.0685</span>,  <span class="number">0.1026</span>,  <span class="number">0.1754</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.1691</span>, -<span class="number">0.0790</span>,  <span class="number">0.2617</span>],</span><br><span class="line">          [ <span class="number">0.1956</span>,  <span class="number">0.1477</span>,  <span class="number">0.0877</span>],</span><br><span class="line">          [ <span class="number">0.0538</span>, -<span class="number">0.3091</span>,  <span class="number">0.2030</span>]]]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([ <span class="number">0.2355</span>,  <span class="number">0.2949</span>, -<span class="number">0.1283</span>, -<span class="number">0.0848</span>,  <span class="number">0.2027</span>, -<span class="number">0.3331</span>],</span><br><span class="line">       requires_grad=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[ <span class="number">2.0555e-02</span>, -<span class="number">2.1445e-02</span>, -<span class="number">1.7981e-02</span>,  ..., -<span class="number">2.3864e-02</span>,</span><br><span class="line">          <span class="number">8.5149e-03</span>, -<span class="number">6.2071e-04</span>],</span><br><span class="line">        [-<span class="number">1.1755e-02</span>,  <span class="number">1.0010e-02</span>,  <span class="number">2.1978e-02</span>,  ...,  <span class="number">1.8433e-02</span>,</span><br><span class="line">          <span class="number">7.1362e-03</span>, -<span class="number">4.0951e-03</span>],</span><br><span class="line">        [ <span class="number">1.6187e-02</span>,  <span class="number">2.1623e-02</span>,  <span class="number">1.1840e-02</span>,  ...,  <span class="number">5.7059e-03</span>,</span><br><span class="line">         -<span class="number">2.7165e-02</span>,  <span class="number">1.3463e-03</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [-<span class="number">3.2552e-03</span>,  <span class="number">1.7277e-02</span>, -<span class="number">1.4907e-02</span>,  ...,  <span class="number">7.4232e-03</span>,</span><br><span class="line">         -<span class="number">2.7188e-02</span>, -<span class="number">4.6431e-03</span>],</span><br><span class="line">        [-<span class="number">1.9786e-02</span>, -<span class="number">3.7382e-03</span>,  <span class="number">1.2259e-02</span>,  ...,  <span class="number">3.2471e-03</span>,</span><br><span class="line">         -<span class="number">1.2375e-02</span>, -<span class="number">1.6372e-02</span>],</span><br><span class="line">        [-<span class="number">8.2350e-03</span>,  <span class="number">4.1301e-03</span>, -<span class="number">1.9192e-03</span>,  ..., -<span class="number">2.3119e-05</span>,</span><br><span class="line">          <span class="number">2.0167e-03</span>,  <span class="number">1.9528e-02</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([ <span class="number">0.0162</span>, -<span class="number">0.0146</span>, -<span class="number">0.0218</span>,  <span class="number">0.0212</span>, -<span class="number">0.0119</span>, -<span class="number">0.0142</span>, -<span class="number">0.0079</span>,  <span class="number">0.0171</span>,</span><br><span class="line">         <span class="number">0.0205</span>,  <span class="number">0.0164</span>], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><code>net.named_parameters</code> 可同时返回可学习的参数及名称</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,parameters <span class="keyword">in</span> net.named_parameters():</span><br><span class="line"></span><br><span class="line"><span class="comment"># conv1.weight : torch.Size([6, 1, 3, 3])</span></span><br><span class="line"><span class="comment"># conv1.bias : torch.Size([6])</span></span><br><span class="line"><span class="comment"># fc1.weight : torch.Size([10, 1350])</span></span><br><span class="line"><span class="comment"># fc1.bias : torch.Size([10])</span></span><br></pre></td></tr></table></figure><p>forward函数的输入和输出都是Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>) <span class="comment"># 这里的对应前面fforward的输入是32</span></span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">input</span>.size()</span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.Size([1, 1, 32, 32])</span></span><br><span class="line"></span><br><span class="line">out.size()</span><br><span class="line"></span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">30</span>, <span class="number">30</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">15</span>, <span class="number">15</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">1350</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure><p>在反向传播前，先要将所有参数的梯度清零</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad() </span><br><span class="line">out.backward(torch.ones(<span class="number">1</span>,<span class="number">10</span>)) <span class="comment"># 反向传播的实现是PyTorch自动实现的，我们只要调用这个函数即可</span></span><br></pre></td></tr></table></figure><p><strong>注意</strong>：<code>torch.nn</code> 只支持 <code>mini-batches</code>，不支持一次只输入一个样本，即一次必须是一个batch。也就是说，就算我们输入一个样本，也会对样本进行分批，所以，所有的输入都会增加一个维度，我们对比下刚才的 <code>input</code>，<code>nn</code> 中定义为3维，但是我们人工创建时多增加了一个维度，变为了4维，最前面的1即为batch-size。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>在nn中PyTorch还预制了常用的损失函数，下面我们用MSELoss用来计算均方误差：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y = torch.arange(<span class="number">0</span>,<span class="number">10</span>).view(<span class="number">1</span>,<span class="number">10</span>).<span class="built_in">float</span>()</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(out, y)</span><br><span class="line"><span class="comment">#loss是个scalar，我们可以直接用item获取到他的python类型的数值</span></span><br><span class="line"><span class="built_in">print</span>(loss.item()) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 28.92203712463379</span></span><br></pre></td></tr></table></figure><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：</p><p><code>weight = weight - learning_rate * gradient</code></p><p>在 <code>torch.optim</code> 中实现大多数的优化方法，例如 RMSProp、Adam、SGD等，下面我们使用SGD做个简单的样例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim</span><br><span class="line"></span><br><span class="line">out = net(<span class="built_in">input</span>) <span class="comment"># 这里调用的时候会打印出我们在forword函数中打印的x的大小</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(out, y)</span><br><span class="line"><span class="comment">#新建一个优化器，SGD只需要要调整的参数和学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 先梯度清零(与net.zero_grad()效果一样)</span></span><br><span class="line">optimizer.zero_grad() </span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment">#更新参数</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><p>这样，神经网络的数据的一个完整的传播就已经通过PyTorch实现了。</p><h1 id="深度学习基础"><a href="#深度学习基础" class="headerlink" title="深度学习基础"></a>深度学习基础</h1><h2 id="监督学习和无监督学习"><a href="#监督学习和无监督学习" class="headerlink" title="监督学习和无监督学习"></a>监督学习和无监督学习</h2><p>监督学习、无监督学习、半监督学习、强化学习是我们日常接触到的常见的四个机器学习方法：</p><ul><li>监督学习：通过已有的训练样本（即已知数据以及其对应的输出）去训练得到一个最优模型（这个模型属于某个函数的集合，最优则表示在某个评价准则下是最佳的），再利用这个模型将所有的输入映射为相应的输出。</li><li>无监督学习：它与监督学习的不同之处，在于我们事先没有任何训练样本，而需要直接对数据进行建模。</li><li>半监督学习 ：在训练阶段结合了大量未标记的数据和少量标签数据。与使用所有标签数据的模型相比，使用训练集的训练模型在训练时可以更为准确。</li><li>强化学习：我们设定一个回报函数（reward function），通过这个函数来确认否越来越接近目标，类似我们训练宠物，如果做对了就给他奖励，做错了就给予惩罚，最后来达到我们的训练目的。</li></ul><p>这里我们只着重介绍监督学习，因为我们后面的绝大部们课程都是使用的监督学习的方法，在训练和验证时输入的数据既包含输入x，又包含x对应的输出y，即学习数据已经事先给出了正确答案。</p><h2 id="线性回归-（Linear-Regreesion）"><a href="#线性回归-（Linear-Regreesion）" class="headerlink" title="线性回归 （Linear Regreesion）"></a>线性回归 （Linear Regreesion）</h2><p>这里不解释具体原理，直接看写法，体会训练过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意，这里我们使用了一个新库叫 seaborn 如果报错找不到包的话请使用pip install seaborn 来进行安装</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Linear, Module, MSELoss</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面我生成一些随机的点，来作为我们的训练数据，回归：y = 5*x + 7</span></span><br><span class="line">x = np.random.rand(<span class="number">256</span>)</span><br><span class="line">noise = np.random.randn(<span class="number">256</span>) / <span class="number">4</span></span><br><span class="line">y = x * <span class="number">5</span> + <span class="number">7</span> + noise</span><br><span class="line">df = pd.DataFrame()</span><br><span class="line">df[<span class="string">&#x27;x&#x27;</span>] = x</span><br><span class="line">df[<span class="string">&#x27;y&#x27;</span>] = y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们随机生成了一些点，下面将使用PyTorch建立一个线性的模型来对其进行拟合，这就是所说的训练的过程，由于只有一层线性模型，所以我们就直接使用了:</span></span><br><span class="line">model=Linear(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 其中参数(1,1)代表输入输出的特征(feature)数量都是1</span></span><br><span class="line"><span class="comment"># Linear 模型的表达式是y=wx+b，其中w代表权重，b代表偏置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数我们使用均方损失函数</span></span><br><span class="line">criterion = MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器我们选择最常见的优化方法 SGD，就是每一次迭代计算 mini-batch 的梯度，然后对参数进行更新，学习率 0.01</span></span><br><span class="line">optim = SGD(model.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练3000次</span></span><br><span class="line">epochs = <span class="number">3000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备训练数据: x_train, y_train 的形状是(256, 1)， </span></span><br><span class="line"><span class="comment"># 代表mini-batch大小为256，feature为1. astype(&#x27;float32&#x27;) 是为了下一步可以直接转换为 torch.float</span></span><br><span class="line">x_train = x.reshape(-<span class="number">1</span>, <span class="number">1</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">y_train = y.reshape(-<span class="number">1</span>, <span class="number">1</span>).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># 整理输入和输出的数据，这里输入和输出一定要是torch的Tensor类型</span></span><br><span class="line">    inputs = torch.from_numpy(x_train)</span><br><span class="line">    labels = torch.from_numpy(y_train)</span><br><span class="line">    <span class="comment">#使用模型进行预测</span></span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    <span class="comment">#梯度置0，否则会累加</span></span><br><span class="line">    optim.zero_grad()</span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># 使用优化器默认方法优化</span></span><br><span class="line">    optim.step()</span><br><span class="line">    <span class="keyword">if</span> (i%<span class="number">100</span>==<span class="number">0</span>):</span><br><span class="line">        <span class="comment">#每 100次打印一下损失函数，看看效果</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch &#123;&#125;, loss &#123;:1.4f&#125;&#x27;</span>.<span class="built_in">format</span>(i,loss.data.item()))</span><br></pre></td></tr></table></figure><p>训练完成了，看一下训练的成果是多少。用 <code>model.parameters()</code> 提取模型参数。 $w$， $b$ 是我们所需要训练的模型参数，我们期望的数据 $w=5$，$b=7$ 可以做一下对比</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[w, b] = model.parameters()</span><br><span class="line"><span class="built_in">print</span> (w.item(),b.item())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.994358062744141 7.0252156257629395</span></span><br></pre></td></tr></table></figure><h2 id="损失函数-Loss-Function"><a href="#损失函数-Loss-Function" class="headerlink" title="损失函数(Loss Function)"></a>损失函数(Loss Function)</h2><p>损失函数（loss function）是用来估量模型的预测值(我们例子中的output)与真实值（例子中的y_train）的不一致程度，它是一个非负实值函数，损失函数越小，模型的鲁棒性就越好。 我们训练模型的过程，就是通过不断的迭代计算，使用梯度下降的优化算法，使得损失函数越来越小。损失函数越小就表示算法达到意义上的最优。</p><p>这里有一个重点：因为PyTorch是使用mini-batch来进行计算的，所以损失函数的计算出来的结果已经对mini-batch取了平均。</p><p>常见（PyTorch内置）的损失函数有以下几个：</p><h3 id="nn-L1Loss"><a href="#nn-L1Loss" class="headerlink" title="nn.L1Loss:"></a>nn.L1Loss:</h3><p>输入x和目标y之间差的绝对值，要求 x 和 y 的维度要一样（可以是向量或者矩阵），得到的 loss 维度也是对应一样的</p><script type="math/tex; mode=display">loss(x,y)=1/n\sum|x_i-y_i|</script><h3 id="nn-NLLLoss"><a href="#nn-NLLLoss" class="headerlink" title="nn.NLLLoss:"></a>nn.NLLLoss:</h3><p>用于多分类的负对数似然损失函数$loss(x, class) = -x[class]$；</p><p>NLLLoss中如果传递了weights参数，会对损失进行加权，公式就变成了</p><script type="math/tex; mode=display">loss(x, class) = -weights[class] * x[class]</script><h3 id="n-MSELoss"><a href="#n-MSELoss" class="headerlink" title="n.MSELoss:"></a>n.MSELoss:</h3><p>均方损失函数 ，输入x和目标y之间均方差</p><script type="math/tex; mode=display">loss(x,y)=1/n\sum(x_i-y_i)^2</script><h3 id="nn-CrossEntropyLoss"><a href="#nn-CrossEntropyLoss" class="headerlink" title="nn.CrossEntropyLoss:"></a>nn.CrossEntropyLoss:</h3><p>多分类用的交叉熵损失函数，LogSoftMax 和 NLLLoss 集成到一个类中，会调用 nn.NLLLoss 函数，我们可以理解为 CrossEntropyLoss()=log_softmax() + NLLLoss()</p><script type="math/tex; mode=display"> \begin{aligned} loss(x, class) &= -\text{log}\frac{exp(x[class])}{\sum_j exp(x[j]))}\ &= -x[class] + log(\sum_j exp(x[j])) \end{aligned}</script><p>因为使用了NLLLoss，所以也可以传入weight参数，这时loss的计算公式变为：</p><script type="math/tex; mode=display">loss(x, class) = weights[class] * (-x[class] + log(\sum_j exp(x[j])))</script><p>所以一般多分类的情况会使用这个损失函数；</p><h3 id="nn-BCELoss"><a href="#nn-BCELoss" class="headerlink" title="nn.BCELoss:"></a>nn.BCELoss:</h3><p>计算 x 与 y 之间的二进制交叉熵。$loss(o,t)=-\frac{1}{n}\sum_i(t[i] <em>log(o[i])+(1-t[i])</em> log(1-o[i]))$ 与NLLLoss类似，也可以添加权重参数：</p><script type="math/tex; mode=display">loss(o,t)=-\frac{1}{n}\sum_iweights[i] *(t[i]* log(o[i])+(1-t[i])* log(1-o[i]))</script><p>用的时候需要在该层前面加上 Sigmoid 函数。</p><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>在介绍损失函数的时候我们已经说了，梯度下降是一个使损失函数越来越小的优化算法，在无求解机器学习算法的模型参数，即约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一。所以梯度下降是我们目前所说的机器学习的核心，了解了它的含义，也就了解了机器学习算法的含义。</p><h3 id="Mini-batch的梯度下降法"><a href="#Mini-batch的梯度下降法" class="headerlink" title="Mini-batch的梯度下降法"></a>Mini-batch的梯度下降法</h3><p>对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候处理速度会很慢，而且也不可能一次的载入到内存或者显存中，所以我们会把大数据集分成小数据集，一部分一部分的训练，这个训练子集即称为Mini-batch。 在PyTorch中就是使用这种方法进行的训练，可以看看上一章中关于dataloader的介绍里面的batch_size就是我们一个Mini-batch的大小。</p><p>为了介绍的更简洁，使用 吴恩达老师的 <a href="https://www.deeplearning.ai/deep-learning-specialization/">deeplearning.ai</a> 课程板书。</p><p>对于普通的梯度下降法，一个epoch只能进行一次梯度下降；而对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降。 <img src="https://handbook.pytorch.wiki/chapter2/2.png" alt="img"> 普通的batch梯度下降法和Mini-batch梯度下降法代价函数的变化趋势，如下图所示： <img src="https://handbook.pytorch.wiki/chapter2/3.png" alt="img"></p><ul><li><p>如果训练样本的大小比较小时，能够一次性的读取到内存中，那我们就不需要使用Mini-batch，</p></li><li><p>如果训练样本的大小比较大时，一次读入不到内存或者现存中，那我们必须要使用 Mini-batch来分批的计算 </p></li><li>Mini-batch size的计算规则如下，在内存允许的最大情况下使用2的N次方个size <img src="https://handbook.pytorch.wiki/chapter2/4.png" alt="img"></li></ul><p><code>torch.optim</code>是一个实现了各种优化算法的库。大部分常用优化算法都有实现，我们直接调用即可。</p><h3 id="torch-optim-SGD"><a href="#torch-optim-SGD" class="headerlink" title="torch.optim.SGD"></a>torch.optim.SGD</h3><p>随机梯度下降算法，带有动量（momentum）的算法作为一个可选参数可以进行设置，样例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#lr参数为学习率，对于SGD来说一般选择0.1 0.01.0.001，如何设置会在后面实战的章节中详细说明</span></span><br><span class="line"><span class="comment">##如果设置了momentum，就是带有动量的SGD，可以不设置</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h3 id="torch-optim-RMSprop"><a href="#torch-optim-RMSprop" class="headerlink" title="torch.optim.RMSprop"></a>torch.optim.RMSprop</h3><p>除了以上的带有动量Momentum梯度下降法外，RMSprop（root mean square prop）也是一种可以加快梯度下降的算法，利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，使其梯度下降的速度变得更快</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#我们的课程基本不会使用到RMSprop所以这里只给一个实例</span></span><br><span class="line">optimizer = torch.optim.RMSprop(model.parameters(), lr=<span class="number">0.01</span>, alpha=<span class="number">0.99</span>)</span><br></pre></td></tr></table></figure><h3 id="torch-optim-Adam"><a href="#torch-optim-Adam" class="headerlink" title="torch.optim.Adam"></a>torch.optim.Adam</h3><p>Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里的lr，betas，还有eps都是用默认值即可，所以Adam是一个使用起来最简单的优化方法</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>, betas=(<span class="number">0.9</span>, <span class="number">0.999</span>), eps=<span class="number">1e-08</span>)</span><br></pre></td></tr></table></figure><h2 id="方差-偏差"><a href="#方差-偏差" class="headerlink" title="方差/偏差"></a>方差/偏差</h2><ul><li>偏差度量了学习算法的期望预测与真实结果的偏离程序，即刻画了学习算法本身的拟合能力</li><li>方差度量了同样大小的训练集的变动所导致的学习性能的变化，即模型的泛化能力 <img src="https://handbook.pytorch.wiki/chapter2/5.png" alt="img"></li></ul><p>从图中我们可以看出 - 高偏差（high bias）的情况，一般称为欠拟合（underfitting），即我们的模型并没有很好的去适配现有的数据，拟合度不够。 - 高方差（high variance）的情况一般称作过拟合（overfitting），即模型对于训练数据拟合度太高了，失去了泛化的能力。</p><p>如何解决这两种情况呢？</p><ul><li><p>欠拟合： </p><ul><li>增加网络结构，如增加隐藏层数目； </li><li>训练更长时间；</li><li>寻找合适的网络架构，使用更大的NN结构；</li></ul></li><li><p>过拟合 ： </p><ul><li>使用更多的数据；</li><li>正则化（ regularization）； </li><li>寻找合适的网络结构；</li></ul></li></ul><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>利用正则化来解决High variance 的问题，正则化是在 Cost function 中加入一项正则化项，惩罚模型的复杂度，这里我们简单的介绍一下正则化的概念</p><h3 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h3><p>损失函数基础上加上权重参数的绝对值 $L=E_{in}+\lambda{\sum_j} \left|w_j\right|$；</p><h3 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h3><p>损失函数基础上加上权重参数的平方和 $L=E_{in}+\lambda{\sum_j} w^2_j$；</p><p>需要说明的是：$L_1$ 相比于 $L_2$ 会更容易获得稀疏解。</p><h1 id="卷积神经网络经典模型LeNet-5"><a href="#卷积神经网络经典模型LeNet-5" class="headerlink" title="卷积神经网络经典模型LeNet-5"></a>卷积神经网络经典模型LeNet-5</h1><p>卷积神经网路的开山之作，麻雀虽小，但五脏俱全，卷积层、pooling层、全连接层，这些都是现代CNN网络的基本组件 - 用卷积提取空间特征； </p><ul><li>由空间平均得到子样本； </li><li>用 tanh 或 sigmoid 得到非线性； </li><li>用 multi-layer neural network（MLP）作为最终分类器；</li><li>层层之间用稀疏的连接矩阵，以避免大的计算成本。 <img src="https://handbook.pytorch.wiki/chapter2/lenet5.jpg" alt="img"></li></ul><p>输入：图像Size为32*32。</p><p>输出：10个类别，分别为0-9数字的概率</p><ol><li>C1层是一个卷积层，有6个卷积核（提取6种局部特征），核大小为5 * 5</li><li>S2层是pooling层，下采样（区域:2 * 2 ）降低网络训练参数及模型的过拟合程度。</li><li>C3层是第二个卷积层，使用16个卷积核，核大小:5 * 5 提取特征</li><li>S4层也是一个pooling层，区域:2*2</li><li>C5层是最后一个卷积层，卷积核大小:5 * 5 卷积核种类:120</li><li>最后使用全连接层，将C5的120个特征进行分类，最后输出0-9的概率</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet5</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet5, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span></span><br><span class="line">        <span class="comment"># kernel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>) <span class="comment"># 这里论文上写的是conv,官方教程用了线性层</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">num_flat_features</span>(<span class="params">self, x</span>):</span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = LeNet5()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br><span class="line"></span><br><span class="line"><span class="comment"># LeNet5(</span></span><br><span class="line"><span class="comment">#   (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class="line"><span class="comment">#   (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=400, out_features=120, bias=True)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=120, out_features=84, bias=True)</span></span><br><span class="line"><span class="comment">#   (fc3): Linear(in_features=84, out_features=10, bias=True)</span></span><br><span class="line"><span class="comment"># )</span></span><br></pre></td></tr></table></figure><h1 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h1><p><a href="http://www.feiguyunai.com/index.php/2019/06/13/python-ml-pytorch/">《Python深度学习基于PyTorch》 | Python技术交流与分享 (feiguyunai.com)</a></p><p><a href="https://github.com/ShusenTang/Dive-into-DL-PyTorch">ShusenTang/Dive-into-DL-PyTorch: 本项目将《动手学深度学习》(Dive into Deep Learning)原书中的MXNet实现改为PyTorch实现。 (github.com)</a></p>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络简介</title>
      <link href="/2022/11/07/network.html"/>
      <url>/2022/11/07/network.html</url>
      
        <content type="html"><![CDATA[<p><strong>说明</strong>：本文以机器学习中最基本的分类网络为背景，介绍神经网络的基本结构；基本只需要知道这些基本组成便可以着手具体的项目代码，而一些特殊的网络组成，只需遇到时自行搜索学习即可。</p><p>传统<strong>k-近邻（KNN）算</strong>法：</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/k-neighbor.png"                        width="178" height="146.5"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><ul><li><p><strong>问：</strong>绿色是属于方块还是三角？——取决于 k。</p></li><li><p><strong>算法流程：</strong></p><ul><li>（1）计算已知类别数据集中的点与当前点的距离，并依次排序</li><li>（2）选取与当前点距离最小的 k 个点，并确定类别；</li><li>（3）返回前 k 个点出现频率最高的类别作为预测。</li></ul></li></ul><h2 id="设计网络需要考虑"><a href="#设计网络需要考虑" class="headerlink" title="设计网络需要考虑"></a>设计网络需要考虑</h2><ul><li>数据的预处理与初始化如何更高效？</li><li>网络结构：隐藏层层数、每层神经元个数？</li><li>损失函数？正则化项？</li><li>优化策略？</li></ul><h2 id="（全连接）神经网路"><a href="#（全连接）神经网路" class="headerlink" title="（全连接）神经网路"></a>（全连接）神经网路</h2><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/all.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="数据预处理和参数初始化"><a href="#数据预处理和参数初始化" class="headerlink" title="数据预处理和参数初始化"></a>数据预处理和参数初始化</h3><ul><li>一般对输入数据进行预处理或归一化（例如映射到 $[0,1]$ 范围内），再作为网络输入；</li><li>对网络参数初始化时进行随机初始化（尽量浮动小一些，类似初始学习率也取很小）。</li></ul><h3 id="线性函数（得分函数）"><a href="#线性函数（得分函数）" class="headerlink" title="线性函数（得分函数）"></a>线性函数（得分函数）</h3><p>​        假设分类有10个类别，权重和偏移分别为 $W\in\mathbb{R}^{10\times d},b\in\mathbb{R}^{10},x\in\mathbb{R}^d$，得分函数即为</p><script type="math/tex; mode=display">f(x,W)=W x+b:input \to score,</script><p>相当于每个类别、每个像素点对应不同参数权重。</p><p>​        事实上，这个权重 $W$、偏移 $b$ 是上面网络中层与层之间连线部分计算的线性部分：从某一层输出，经过线性变换之后作为下一层的输入。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>​        <strong>目的</strong>：如果只是一直的线性变换，那只是简单的线性拟合，无法应对非线性数据；</p><p>​        <strong>方法</strong>：经过上述线性变换后，在传输到下一组神经元之前，进行非线性变换，也即<strong>激活</strong>。事实上这个激活函数就是上面每层网络中的圆圈部分。下面是两个最常用的两种激活函数：</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/sigmod.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>​        用于监督与反向传播，衡量计算当前得分的权重的好坏，例如这里 ：</p><script type="math/tex; mode=display">L_i=\sum_{j\neq y_i}\max(0,s_j-s_{y_i}+1)+\lambda R(W)</script><p>后面 $\lambda R(W)$ 为正则项，是为了削减过拟合。</p><h3 id="softmax-分类器"><a href="#softmax-分类器" class="headerlink" title="$softmax$ 分类器"></a>$softmax$ 分类器</h3><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/softmax.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p>从而计算损失，如图中取的是交叉熵，因为概率越靠近1，损失越小。</p><h3 id="反向传播（可微）"><a href="#反向传播（可微）" class="headerlink" title="反向传播（可微）"></a>反向传播（可微）</h3><p>​        链式法则逐层计算偏导，从网络的输出反向进行到网络的输入，以进行后续的优化，例如<strong>梯度下降法</strong>：</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/grad.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="Drop-out"><a href="#Drop-out" class="headerlink" title="Drop-out"></a>Drop-out</h3><p>​        为了削弱过拟合部分，随机在某些训练步内失活一定的神经元：</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/drop-out.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr>    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn-all.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>​        <strong>目的</strong>：增加关联性，考虑到像素与周围像素是有关联性的；</p><p>​        <strong>策略</strong>：利用卷积块作为权重参数对指定大小的像素块做加权组合；注意，每个颜色通道是单独做卷积。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn-1.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn-11.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn-12.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p><strong>边缘填充</strong>，是因为边界在做卷积时，边缘只计算一次，但是内部可能计算多次，为了平衡重要性，在边缘添加一圈0。</p><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>​        <strong>效果</strong>：卷积一定层后，可能发生维度爆炸，利用池化层降低维度。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn-2.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn-21.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="特征图变化"><a href="#特征图变化" class="headerlink" title="特征图变化"></a>特征图变化</h3><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/cnn-3.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h3><p>​        可以看到，到第二个卷积层后，一个像素块已经<strong>感受</strong>到了周围像素块的关联性。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/feelfield.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/feelfield2.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p>（可跳过）下面的经典网络只是学习时候遇见，罗列在此。</p><h2 id="经典网络"><a href="#经典网络" class="headerlink" title="经典网络"></a>经典网络</h2><h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/vgg.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="Resnet-残差网络"><a href="#Resnet-残差网络" class="headerlink" title="Resnet 残差网络"></a>Resnet 残差网络</h3><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/renet.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><h3 id="递归神经网络"><a href="#递归神经网络" class="headerlink" title="递归神经网络"></a>递归神经网络</h3><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/rnn.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/rnn2.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><ul><li><p>保留上一步时间的特征，和下一时间特征一起输入到下一层；</p></li><li><p>一般只选择最后一层输出结果。</p></li></ul><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/lstm.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/lstm2.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/lstm3.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/lstm4.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/lstm5.png"                        width="543.75" height="267"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table>]]></content>
      
      
      <categories>
          
          <category> Basic Knowledge </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Basic Knowledge </tag>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>脚本积累</title>
      <link href="/2022/11/07/script.html"/>
      <url>/2022/11/07/script.html</url>
      
        <content type="html"><![CDATA[<p><strong>此博客用来存放、并简单介绍相关数据处理等脚本。</strong></p><h2 id="视频抽帧"><a href="#视频抽帧" class="headerlink" title="视频抽帧"></a>视频抽帧</h2><p><a href="/code/video2images.py">video2images.py</a>：以一定间隔从视频内提取帧；</p><ul><li><p>在第6行修改视频格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> input_path.endswith(<span class="string">&#x27;.MP4&#x27;</span>):</span><br></pre></td></tr></table></figure></li><li><p>在第19行修改图片大小（尽量保持原比例缩放）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame_n = cv2.resize(frame, (<span class="number">1920</span>, <span class="number">1080</span>)) <span class="comment"># (W,H)</span></span><br></pre></td></tr></table></figure></li><li><p>第28、29、30分别为视频输入路径、图片储存文件夹、间隔帧数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input_path = <span class="string">&quot;/path/to/your/video&quot;</span>     <span class="comment"># 视频输入路径</span></span><br><span class="line">save_path = <span class="string">&quot;/path/to/your/image/&quot;</span>     <span class="comment"># 提取图片输出路径</span></span><br><span class="line">frame_interval = <span class="number">10</span>                    <span class="comment"># 抽帧间隔数</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="图片批量重命名"><a href="#图片批量重命名" class="headerlink" title="图片批量重命名"></a>图片批量重命名</h2><p><a href="/code/rename.py">rename.py</a>：将文件夹家内以一定顺序重命名；</p><ul><li><p>第4、5、6行分别为原始图片文件夹、重命名后文件夹、重命名后第一个图片序号</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">&#x27;/path/to/your/image/&#x27;</span>          <span class="comment"># 文件夹路径</span></span><br><span class="line">out_path = <span class="string">&#x27;/path/to/your/new/image/&#x27;</span>  <span class="comment"># 新文件夹路径</span></span><br><span class="line">start = <span class="number">0</span>                              <span class="comment"># 重命名后第一个图片序号</span></span><br></pre></td></tr></table></figure></li><li><p>第9行为命名原则</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">&quot;%05d&quot;</span> % start                  <span class="comment">#5位数 不足前面补零</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="依据mask图像分割"><a href="#依据mask图像分割" class="headerlink" title="依据mask图像分割"></a>依据mask图像分割</h2><p><a href="/code/extract.py">extract.py</a>：这里给出的是依据 <a href="https://github.com/hkchengrex/MiVOS/tree/MiVOS-STCN">MiVOS-STCN</a> 算法分割给出的（红色）mask进行图像分割，输出白色mask、分割后的图片；<strong>需要保持mask与原始图片名字一致！</strong></p><ul><li><p>只需修改第21—24行相关路径即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">original_path = <span class="string">&#x27;/path/to/ori/image/&#x27;</span> <span class="comment"># 原始图片路径</span></span><br><span class="line">ori_mask_path = <span class="string">&#x27;/path/to/ori/mask/&#x27;</span>  <span class="comment"># 原始红色mask路径</span></span><br><span class="line">images_path   = <span class="string">&#x27;/path/to/new/image/&#x27;</span> <span class="comment"># 分割后图片路径</span></span><br><span class="line">masks_path    = <span class="string">&#x27;/path/to/new/image/&#x27;</span> <span class="comment"># 修改颜色后mask路径</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="调整图像分辨率"><a href="#调整图像分辨率" class="headerlink" title="调整图像分辨率"></a>调整图像分辨率</h2><p><a href="/code/lowresolution.py">lowresolution.py</a>：降低图像分辨率</p><ul><li><p>修改5、6行路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sourceDir = os.path.join(curDir, <span class="string">&#x27;/path/to/ori/image/&#x27;</span>)</span><br><span class="line">resultDir = os.path.join(curDir, <span class="string">&#x27;/path/to/new/image/&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li><p>第13行修改到指定分辨率（尽量保持原始比例）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pic_n = cv2.resize(pic, (<span class="number">960</span>, <span class="number">540</span>)) <span class="comment"># (W,H)</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="修改图片通道数"><a href="#修改图片通道数" class="headerlink" title="修改图片通道数"></a>修改图片通道数</h2><p><a href="/code/rgb2rgba.py">rgb2rgba.py</a>：有些项目需要<code>RGB</code>通道，有些则需要<code>RGBA</code>通道</p><ul><li><p>修改4、5行路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path      = <span class="string">&quot;/path/to/ori/image/&quot;</span>     <span class="comment"># 原始路径</span></span><br><span class="line">save_path = <span class="string">&#x27;/path/to/new/image/&#x27;</span>     <span class="comment"># 保存路径</span></span><br></pre></td></tr></table></figure></li><li><p>第13行可以修改转换后通道数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pimg = img.convert(<span class="string">&quot;RGB&quot;</span>)  <span class="comment"># 4通道转化为rgb三通道</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="提取colmap匹配的有效图片"><a href="#提取colmap匹配的有效图片" class="headerlink" title="提取colmap匹配的有效图片"></a>提取colmap匹配的有效图片</h2><p><a href="/code/valid_imgs_from_imgstxt.py">valid_imgs_from_imgstxt.py</a>：colmap获取位姿可能因为某些原因造成部分图片无法匹配，这对有些项目影响很大！造成代码一些数组序号出问题、甚至可能无法运行，这里建议提取有效图片</p><ul><li><p>修改第25—27行相关路径即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">file_name   = <span class="string">&quot;/path/to/colmap/text/images.txt&quot;</span> <span class="comment"># images.txt 文件</span></span><br><span class="line">input_path  = <span class="string">&quot;/path/to/ori/image/&quot;</span>             <span class="comment"># 原始图片路径</span></span><br><span class="line">output_path = <span class="string">&quot;/path/to/valid/image/&quot;</span>           <span class="comment"># 提取后有效图片路径</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="图像转GIF"><a href="#图像转GIF" class="headerlink" title="图像转GIF"></a>图像转GIF</h2><p><a href="/code/image2gif.py">image2gif.py</a>：将一定顺序的图片序列转换为GIF动图</p><ul><li><p>修改13—15行相关路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img_dir  = <span class="string">&#x27;/path/to/image&#x27;</span>  <span class="comment"># 图片路径</span></span><br><span class="line">duration = <span class="number">0.05</span>              <span class="comment"># 图片间隔,每秒20帧,即1/20</span></span><br><span class="line">gif_name = img_dir+<span class="string">&#x27;.gif&#x27;</span>    <span class="comment"># 输出gif名字</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="图像转视频"><a href="#图像转视频" class="headerlink" title="图像转视频"></a>图像转视频</h2><p><a href="/code/image2video.py">image2video.py</a>：将一定顺序的图片序列转换为视频</p><ul><li><p>修改16行帧率、17行视频存储路径及名字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fps = <span class="number">30</span></span><br><span class="line">file_path = <span class="string">r&quot;/pathto/video/name.mp4&quot;</span> </span><br></pre></td></tr></table></figure></li><li><p>第30行图片路径及分辨率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">picvideo(<span class="string">r&#x27;/path/to/image/&#x27;</span>, (<span class="number">1920</span>, <span class="number">1080</span>)) <span class="comment"># (W,H)</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="相机位姿添加噪声"><a href="#相机位姿添加噪声" class="headerlink" title="相机位姿添加噪声"></a>相机位姿添加噪声</h2><p><a href="/code/add_noise_in_txt.py">add_noise_in_txt.py</a>：直接给colamp跑出的 <code>image.txt</code> 添加高斯噪声</p><ul><li><p>修改第9、10行噪声方差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sigma_r = <span class="number">5.0</span> <span class="comment"># 旋转矩阵的噪声方差</span></span><br><span class="line">sigma_t = <span class="number">0.1</span> <span class="comment"># 位移向量的噪声方差</span></span><br></pre></td></tr></table></figure></li><li><p>修改第49、50行相关路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file_name = <span class="string">&quot;/path/to/colmap/text/images.txt&quot;</span> <span class="comment"># 原始colmap的image.tx</span></span><br><span class="line">output_name = <span class="string">&quot;/path/to/new/images.txt&quot;</span>       <span class="comment"># 添加噪声后的image.txt路径</span></span><br></pre></td></tr></table></figure></li></ul><p><a href="/code/add_noise_in_json.py">add_noise_in_json.py</a>：给 <code>tansform.json</code> 添加高斯噪声</p><ul><li><p>修改第41、42行噪声方差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sigma_r = <span class="number">5.0</span> <span class="comment"># 旋转矩阵的噪声方差</span></span><br><span class="line">sigma_t = <span class="number">0.1</span> <span class="comment"># 位移向量的噪声方差</span></span><br></pre></td></tr></table></figure></li><li><p>修改第98、99行相关路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file_name = <span class="string">&quot;/path/to/transform.json&quot;</span>         <span class="comment"># 原始位姿</span></span><br><span class="line">output_name = <span class="string">&quot;/path/to/new/transform.json&quot;</span>   <span class="comment"># 添加噪声后</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Code </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Script </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NeRF数据采集与处理</title>
      <link href="/2022/11/06/nerf.html"/>
      <url>/2022/11/06/nerf.html</url>
      
        <content type="html"><![CDATA[<h1 id="拍摄要求"><a href="#拍摄要求" class="headerlink" title="拍摄要求"></a>拍摄要求</h1><ul><li>拍摄尽可能同一时间段拍完，避免巨变的光照条件变化、曝光失常、焦点失焦等问题；</li><li>可以选择拍摄图片，但需保证不同图片的相机焦距一定，避免手机滤镜、美颜等磨去纹理等；<strong>建议</strong>拍摄视频，可以保证相邻图片直接连续性；</li><li>小物件，可以物品为球心，在半球式多视角拍摄图片；对于较大物品，无法做到半球式拍摄顶部，可以柱面或部分球面的形式拍摄，但重建效果对于未采集区域必然是不好的；</li></ul><h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><p>（此处我提供了一些 <code>python</code> 脚本处理，例如抽帧、降分辨率等，具体请见：脚本积累）</p><ul><li>拍摄为视频时：保持镜头的连续性，以一定间隔进行抽帧（保证相邻图片特征匹配良好），并剔除失焦模糊、曝光失常等无效图片；</li><li>必要时可以将图片同比例的缩小；</li><li>（可选）如果只想单独重建物体，可以进行图像分割，将想要重建的物品抠图出来（PS、<a href="https://github.com/hkchengrex/MiVOS/tree/MiVOS-STCN">MiVOS-STCN</a>等方法）；</li></ul><h1 id="相机内外参"><a href="#相机内外参" class="headerlink" title="相机内外参"></a>相机内外参</h1><p>我们利用 <a href="(http://colmap.github.io/">colmap</a>) 图形界面获取相机内外参：</p><ul><li><p>最好这里保证如下文件结构：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+ --- scene               <span class="comment"># 待合成场景</span></span><br><span class="line">|     + --- image        <span class="comment"># 图片文件夹</span></span><br><span class="line">|     + --- mask         <span class="comment"># 如果进行了语义分割，mask文件夹</span></span><br><span class="line">|     + --- database.db  <span class="comment"># 从此开始,下述文件为位姿获取时生成</span></span><br><span class="line">|     + --- sparse       <span class="comment"># 相机位姿的二进制文件</span></span><br><span class="line">|     + --- text         <span class="comment"># 相机外参的.txt格式文件 </span></span><br><span class="line">|     + --- project.ini</span><br></pre></td></tr></table></figure></li><li><p>菜单栏 <code>File-&gt;New project</code>，第一栏创建 <code>database.db</code> 二进制进程文件，第二栏添加 <code>image</code> 图片文件夹路径；</p></li><li><p>菜单栏 <code>Processing-&gt;Feature extraction</code>，将 <code>camera model</code> 调整为 <code>PINHOLE</code>，选中下面的 <code>Shared for all images</code>（这也就是为什么我们要求不要改变内参，避免不必要的麻烦）。（如果有 <code>mask</code>，可以导入对应文件夹路径；如果有多个 GPU，可以在下面选择 <code>gpu_index</code> 参数）最后点击 <code>Extract</code> 提取特征；</p></li><li><p>菜单栏 <code>Processing-&gt;Feature matching-&gt;Exhaustive-&gt;Run</code>；</p></li><li><p>菜单栏 <code>Reconstruction-&gt;Automatic reconstruction</code>，<code>Workspace</code> 导入 <code>scene</code> 文件夹，<code>Image folder</code> 导入<code>image</code> 文件夹，选中 <code>Shared intrinsics</code>，<strong>取消</strong> <code>Dense model</code>，然后 <code>Run</code>；</p></li><li><p>直观的，你可以导出看看相机内外参，<code>File-&gt;Export model as text</code>；</p></li><li><p>关闭前会让你保存一个 <code>project.ini</code> 文件。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> NeRF </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeRF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Becoming Jane》(成为简·奥斯汀)</title>
      <link href="/2022/11/03/becoming-jane.html"/>
      <url>/2022/11/03/becoming-jane.html</url>
      
        <content type="html"><![CDATA[<h1 id="Paradise的电影乐园-传记-爱情"><a href="#Paradise的电影乐园-传记-爱情" class="headerlink" title="#Paradise的电影乐园# 传记 爱情"></a>#Paradise的电影乐园# 传记 爱情</h1><p>导演：Julian Jarrold<br>主演：Anne Hathaway，James McAvoy<br>上映时间：2007年03月09日</p><p><strong>“</strong><br><strong>Sometimes affection is a shy flower that takes time to blossom.</strong><br><strong>”</strong><br><strong>“</strong><br><strong>Affection is desirable,</strong><br><strong>Money is absolutely indispensable.</strong><br><strong>”</strong>  </p><p>她的心被扰乱了，只是一阵 夏日的狂风。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/becoming_jane_3.jpg"                        width="511.2" height="556"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p>在那个英式典雅的时代，</p><p>一个安静的清晨，仿佛古典戏剧一般的开始，一切充满着田园牧歌与优雅的浪漫，</p><p>随着简的钢琴声的响起，群鸟惊飞，众人惊起，从一开始就奠定了简与保守英国乡村生活的格格不入。  </p><p>末了，已是作家的简偶然瞥见了前来观摩自己作品的汤姆，如今却已身为人父，</p><p>当女儿要求简为大家朗读作品时，汤姆严厉的呵斥：“简！” </p><p>错愕写满了简的脸上，</p><p>这是一个无法抵御的桥段，</p><p>本以为一切走向了终结，本以为终是尘埃落定，</p><p>谁料却是一直绵延交织在两人的余生——汤姆以简的名字为女儿命名，而简所写的故事也藏着他们的影子。</p><p>爱，带着观望般的珍重，永远不会厌倦和衰灭，融漾在淡淡的牵念和释然的遗憾之间，绵长一生，徘徊一生……   </p><p></p><p>世俗阻挡的爱情，古往今来的文人骚客写出了太多太多，或壮烈决绝，或凄美哀婉。</p><p>不是每个人都能如罗密欧那般欧式的决绝，如祝英台般中式的缠绵，</p><p>在此，更多的是一种生活的平静，无论是抗争还是妥协。   </p><p></p><p><strong>并不是只有激情迸发时弃世孤行的爱情才最真挚可贵，</strong></p><p><strong>若把世界逼堵到只容两个人立足，</strong></p><p><strong>结局也许早已违背当时的初衷。</strong></p><p><strong>若有天长地久的厮守，也必有终身不忘的情长。</strong></p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/becoming_jane_2.jpg"                        width="840" height="560.7"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table>]]></content>
      
      
      <categories>
          
          <category> Movie </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Paradise的电影乐园 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《L&#39;Argent》(钱)</title>
      <link href="/2022/11/02/largent.html"/>
      <url>/2022/11/02/largent.html</url>
      
        <content type="html"><![CDATA[<h1 id="Paradise的电影乐园-剧情"><a href="#Paradise的电影乐园-剧情" class="headerlink" title="#Paradise的电影乐园# 剧情"></a>#Paradise的电影乐园# 剧情</h1><p>导演：Robert Bresson<br>主演：Christian Patey<br>上映时间：1983年  </p><p><strong>“</strong><br><strong>当你意识到自己的存在和社会的荒谬，</strong><br><strong>而你别无选择时，</strong><br><strong>你会怎么办？</strong><br><strong>他们说</strong><br> <strong>‘ 服从吧，只要你别多管闲事；</strong><br><strong>等着吧，世界很快就会幸福起来。’</strong><br><strong>但我不想等到全世界都幸福，</strong><br><strong>相信我，伊文，那只会等到你变傻，</strong><br><strong>我想现在就得到幸福，用我自己的方法。</strong><br><strong>钱！</strong><br><strong>有形之神，无所不能。</strong><br><strong>”</strong></p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/largent_3.jpg"                        width="691.2" height="388.8"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p>法国导演布列松的最后一部作品，一如既往的极简与冷峻，把一切可能引起情绪波动的镜头都省略，唯余平淡、留白。（困的时候真不能看布列松。）    </p><p>看布列松的电影，就好像在看一条三文鱼放在案板上切割，清晰带血，不留一丝余地。  </p><p>500法郎假钞辗转多人，最后经由一场伪证锤死无辜的伊文以牢狱之灾，但这不是一切的结束，而是冷冽悲剧的开始……虚无伴随左右，毁灭不是推波助澜，而是奔赴相拥的终点。  </p><p><strong>推荐理由：</strong></p><p>《电影手册》上法国导演排行榜上名列第一的导演，其最后一部作品将个人风格发挥到了极致。</p><p>“人物是属于导演理念的工具”，电影中人的眼神之间像隔了一层墙，你无法感受到人的呼吸和情绪的冷暖；</p><p>宛似“木偶人”的动作不会诱导无谓的煽情，不会让你有任何偏见与道德审视；</p><p>环境的先导性与延滞性，只提取结果的决定性瞬间，极尽的留白与省略之能事，画外音的自行填补，</p><p>这种冷峻且客观的极简镜头，只是为了展示最终酷烈且无望的主题。  </p><p>不得不提的就是电影的画面：极具老式的胶卷风格，搭配法式建筑与物品，搭配人物如模特的冷峻，这极简的镜头语言将恰到好处的绝佳构图发挥到了极致，随便抽帧便是一幅妥妥的油画或摄影佳作。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/largent_2.jpg"                        width="635" height="384"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p>纯粹的善良是存在的，救赎的希望也给予了，但，来不及了。</p><p>他高举斧子：“钱在哪里？”，老妇人的沉默换来了伊文在疯狂中挥下了斧子，</p><p>其后，他踉踉跄跄的走出来，连粘满血的裤子都没有换下，径直的走进一家有警察的酒馆，在喝完酒保为其倒下的酒后，自首。</p><p>料峭，所有的一切都崩溃了，既然无法摆脱困境与煎熬，那我选择堕入虚无与毁灭的深渊，拥抱最后的惨淡。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/largent_4.jpg"                        width="597" height="360"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p>钱之下，一切的无能为力、罪恶导向与价值虚无！  </p><p>金钱与权力结构以其固有的“神力”堵住了底层人的生存之路，</p><p>并于百态之下剥夺你仅剩的尊严，</p><p>再于极端情形之下助你踏上一切的罪恶之路，</p><p>就完了么？</p><p>没有，还要在制高点给予你最终的审视、批判你的原罪。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/largent_5.jpg"                        width="480" height="270"/>            </center>        </td>   <!--<center>标签将图片居中-->        <td>            <center>            <img src="/image/movie/largent_6.jpg"                        width="480" height="270"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table>]]></content>
      
      
      <categories>
          
          <category> Movie </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Paradise的电影乐园 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《About Time》(时空恋旅人)</title>
      <link href="/2022/11/01/about_time.html"/>
      <url>/2022/11/01/about_time.html</url>
      
        <content type="html"><![CDATA[<h1 id="Paradise的电影乐园-爱情"><a href="#Paradise的电影乐园-爱情" class="headerlink" title="#Paradise的电影乐园#  爱情"></a>#Paradise的电影乐园#  爱情</h1><p>导演：Richard Curtis</p><p>主演：Domhnall Gleeson，Rachel McAdams</p><p>上映时间：2013年09月04日</p><p><strong>“</strong><br><strong>We’re all traveling through time together</strong><br><strong>every day of our lives.</strong><br><strong>All we can do is</strong><br><strong>do our best to relish this remarkable ride.</strong><br><strong>“</strong>   </p><p>披着科幻超能力外衣的人生爱情小电影。  </p><p>不顾一切要找回认识你的开始、尴尬到不知所措的同行之路、</p><p>不顾一切飞奔回家的普通求婚、每天分别向左向右的地铁站台、</p><p>一场狂风暴雨下荒唐而又甜蜜的婚礼，以及终究是生活的平凡。  </p><p>不要纠结时间悖论的逻辑Bug，去感受另一种生活的交错、平凡与融洽。  </p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/about_time_3.gif"                        width="648" height="269.4"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p><strong>推荐理由：</strong></p><p>初看前半段你会以为是男主超能力的逆袭之路，</p><p>恰恰不然，拥有的能力是为了步入于我而言奢侈的爱情，</p><p>即使我有无限可以容错自身选择的能力，但是选择依然是你，为了遇见你、为了认识你、为了留住你，依然是你；</p><p>虽然我可以选择重新去过每一天，第一次用来经历与度过，第二次则是体验未注意到的小美好，</p><p>但是我终归有着的是当下与你的美好，就像已经经历过一次一样，享受我们这平凡又非凡的生命中每一天。  </p><p>镜头语言是文艺的，角色的内心随着镜头展现的淋漓尽致；另外，配乐是刚刚好的精妙。</p><table frame=void>  <!--使用table标签，且frame=void消除外边框-->    <tr>           <!--<tr>一行的内容<\tr>，<td>一个格子的内容<\td>-->        <td>            <center>            <img src="/image/movie/about_time_2.jpg"                        width="648" height="648"/>            </center>        </td>   <!--<center>标签将图片居中-->    </tr></table><p>穿越的能力会有修改遗憾的可能，这或许是存在于另一维度或者世界的力量，是我们于这个平凡世界里所寄托的无限期冀。  </p><p>如果我们也有穿越时空的能力，每一次遗憾也就会变得有迹可循，离别后的再一次重逢也会很有意义。    </p><p>但是即使已经足够非凡的你我仍然是有着平凡的一生，</p><p>我们可以选择短暂的跳脱并游离于外世，</p><p>不过皆知那不是长久之计，所以尽早地着眼你我前方的美好与未知吧。</p>]]></content>
      
      
      <categories>
          
          <category> Movie </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Paradise的电影乐园 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
